{"cells":[{"cell_type":"markdown","metadata":{"id":"TkjMQljGRQFG"},"source":["# Transformer Vanilla\n","**Based on the class Module 10: Time Series in PyTorch.**  \n","\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."]},{"cell_type":"markdown","metadata":{"id":"Yllf6Ub-RQFJ"},"source":["## Loading Sun Spot Data for a Transformer Time Series\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvQ6vUqbE6r6"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import StandardScaler\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n"]},{"cell_type":"code","source":["import psutil\n","print(\"Memória RAM Total:\", psutil.virtual_memory().total)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32u1Yc3tEput","executionInfo":{"status":"ok","timestamp":1710727849800,"user_tz":180,"elapsed":2,"user":{"displayName":"Ricardo Adley","userId":"12542844481650779199"}},"outputId":"928a02da-aa60-41ee-f8fd-9b6867bf9295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Memória RAM Total: 13609451520\n"]}]},{"cell_type":"code","source":["def read_and_prepare_df(df_path):\n","  df = pd.read_csv(df_path)\n","  df['Data'] = pd.to_datetime(df['Data'])\n","  return df\n","def split_train_test(df,max_date_train,min_date_test):\n","  treino = df.query(\"Data <= @max_date_train\")\n","  teste= df.query(\"Data >= @min_date_test\")\n","  return treino,teste"],"metadata":{"id":"WJJyspeeAIkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_lsd = read_and_prepare_df('https://docs.google.com/uc?export=download&id=1-F71fdeBhScnn01Ev78BGc-ZLGr_WHJR')\n"],"metadata":{"id":"vgAYnHhCAJbm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"us_X4qz3NVh9"},"outputs":[],"source":["# Data Preprocessing\n","df_train,df_test = split_train_test(df_lsd,'2023-07-31 23:00:00','2023-08-01 00:00:00')\n","\n","spots_train = df_train['total_w'].to_numpy().reshape(-1, 1)\n","spots_test = df_test['total_w'].to_numpy().reshape(-1, 1)\n","\n","scaler = StandardScaler()\n","spots_train = scaler.fit_transform(spots_train).flatten().tolist()\n","spots_test = scaler.transform(spots_test).flatten().tolist()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9utrJg62N1P-"},"outputs":[],"source":["# Sequence Data Preparation\n","SEQUENCE_SIZE = 10\n","\n","def to_sequences(seq_size, obs):\n","    x = []\n","    y = []\n","    for i in range(len(obs) - seq_size):\n","        window = obs[i:(i + seq_size)]\n","        after_window = obs[i + seq_size]\n","        x.append(window)\n","        y.append(after_window)\n","    return torch.tensor(x, dtype=torch.float32).view(-1, seq_size, 1), torch.tensor(y, dtype=torch.float32).view(-1, 1)\n","\n","x_train, y_train = to_sequences(SEQUENCE_SIZE, spots_train)\n","x_test, y_test = to_sequences(SEQUENCE_SIZE, spots_test)\n","\n","# Setup data loaders for batch\n","train_dataset = TensorDataset(x_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","\n","test_dataset = TensorDataset(x_test, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"o9TI-mjYTm9u"},"source":["# Position Encoding for Transformers\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wi-bRiyCN7Cw"},"outputs":[],"source":["# Positional Encoding for Transformer\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)"]},{"cell_type":"markdown","metadata":{"id":"jJR-CJLeOzpd"},"source":["# Constructing the Transformer Model\n","\n","\n","* **input_dim**: The dimension of the input data, in this case we use only one input, the number of sunspots.\n","* **d_model**: The number of features in the transformer model's internal representations (also the size of embeddings). This controls how much a model can remember and process.\n","* **nhead**: The number of attention heads in the multi-head self-attention mechanism.\n","* **num_layers**: The number of transformer encoder layers.\n","dropout: The dropout probability.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoT-VFSdOANz","executionInfo":{"status":"ok","timestamp":1710727853002,"user_tz":180,"elapsed":503,"user":{"displayName":"Ricardo Adley","userId":"12542844481650779199"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7674b6f4-5ce3-4507-cf6b-5376e6b782ff"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["# Model definition using Transformer\n","class TransformerModel(nn.Module):\n","    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2, dropout=0.2):\n","        super(TransformerModel, self).__init__()\n","\n","        self.encoder = nn.Linear(input_dim, d_model)\n","        self.pos_encoder = PositionalEncoding(d_model, dropout)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n","        self.decoder = nn.Linear(d_model, 1)\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.pos_encoder(x)\n","        x = self.transformer_encoder(x)\n","        x = self.decoder(x[:, -1, :])\n","        return x\n","\n","model = TransformerModel().to(device)"]},{"cell_type":"markdown","metadata":{"id":"Mi_9wvWWfOGv"},"source":["\n","\n","## Training the Model\n","\n"]},{"cell_type":"code","source":["import psutil\n","memoria_usada = []\n","def capturar_uso_memoria():\n","    # Captura o uso de memória RAM atual\n","    uso_memoria = psutil.virtual_memory().used\n","    memoria_usada.append(uso_memoria)\n"],"metadata":{"id":"6Tqkx6mYPToW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8-mF1OCOLnB","outputId":"0bc1cc4a-5f64-470c-e08f-7f75fc7fc2c3","executionInfo":{"status":"ok","timestamp":1710727880201,"user_tz":180,"elapsed":27202,"user":{"displayName":"Ricardo Adley","userId":"12542844481650779199"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/1000, Validation Loss: 0.1411\n","Epoch 2/1000, Validation Loss: 0.1007\n","Epoch 3/1000, Validation Loss: 0.0945\n","Epoch 4/1000, Validation Loss: 0.1091\n","Epoch 5/1000, Validation Loss: 0.1115\n","Epoch 6/1000, Validation Loss: 0.0935\n","Epoch 7/1000, Validation Loss: 0.0981\n","Epoch 8/1000, Validation Loss: 0.1376\n","Epoch 9/1000, Validation Loss: 0.1107\n","Epoch 10/1000, Validation Loss: 0.1196\n","Early stopping!\n"]}],"source":["# Train the model\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3, verbose=True)\n","\n","epochs = 1000\n","early_stop_count = 0\n","min_val_loss = float('inf')\n","\n","for epoch in range(epochs):\n","    model.train()\n","    for batch in train_loader:\n","        x_batch, y_batch = batch\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(x_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        capturar_uso_memoria()\n","    # Validation\n","    model.eval()\n","    val_losses = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            x_batch, y_batch = batch\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            outputs = model(x_batch)\n","            loss = criterion(outputs, y_batch)\n","            val_losses.append(loss.item())\n","\n","    val_loss = np.mean(val_losses)\n","    scheduler.step(val_loss)\n","\n","    if val_loss < min_val_loss:\n","        min_val_loss = val_loss\n","        early_stop_count = 0\n","    else:\n","        early_stop_count += 1\n","\n","    if early_stop_count >= 5:\n","        print(\"Early stopping!\")\n","        break\n","    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {val_loss:.4f}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HS-lkHvOhXGm"},"source":["We can now evaluate the performance of this model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dE9fco0GOQr6","outputId":"5775ebbd-dc8e-4738-a651-cc54ef21b4ed","executionInfo":{"status":"ok","timestamp":1710727880202,"user_tz":180,"elapsed":14,"user":{"displayName":"Ricardo Adley","userId":"12542844481650779199"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Score (RMSE): 74.5556\n"]}],"source":["# Evaluation\n","model.eval()\n","predictions = []\n","with torch.no_grad():\n","    for batch in test_loader:\n","        x_batch, y_batch = batch\n","        x_batch = x_batch.to(device)\n","        outputs = model(x_batch)\n","        predictions.extend(outputs.squeeze().tolist())\n","\n","rmse = np.sqrt(np.mean((scaler.inverse_transform(np.array(predictions).reshape(-1, 1)) - scaler.inverse_transform(y_test.numpy().reshape(-1, 1)))**2))\n","print(f\"Score (RMSE): {rmse:.4f}\")"]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(observed_values, predicted_values):\n","    # RMSE (Root Mean Squared Error)\n","    rmse = np.sqrt(mean_squared_error(observed_values, predicted_values))\n","\n","    # MSE (Mean Squared Error)\n","    mse = mean_squared_error(observed_values, predicted_values)\n","\n","    # MAE (Mean Absolute Error)\n","    mae = mean_absolute_error(observed_values, predicted_values)\n","\n","    # MAPE (Mean Absolute Percentage Error)\n","    def mean_absolute_percentage_error(observed_values, predicted_values):\n","        return np.mean(np.abs((observed_values - predicted_values) / observed_values)) * 100\n","    mape = mean_absolute_percentage_error(observed_values, predicted_values)\n","\n","    # R² (Coeficiente de Determinação)\n","    r2 = r2_score(observed_values, predicted_values)\n","\n","    # MASE (Mean Absolute Scaled Error) - Necessário calcular os erros do modelo de benchmark\n","    naive_forecast = np.roll(observed_values, 1)  # Utilizando previsão ingênua (shift de 1)\n","    naive_errors = np.abs(observed_values - naive_forecast)\n","    mase = np.mean(np.abs(observed_values - predicted_values) / naive_errors)\n","\n","    # sMAPE (Symmetric Mean Absolute Percentage Error)\n","    def symmetric_mean_absolute_percentage_error(observed_values, predicted_values):\n","        return np.mean(2 * np.abs(observed_values - predicted_values) / (np.abs(observed_values) + np.abs(predicted_values))) * 100\n","    smape = symmetric_mean_absolute_percentage_error(observed_values, predicted_values)\n","\n","    return rmse, mse, mae, mape, r2, mase, smape"],"metadata":{"id":"D1dzZeW2JSh5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","lista_unica = [item for sublist in y_test.numpy().tolist() for item in sublist]\n"],"metadata":{"id":"rrW309NSKVgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmse, mse, mae, mape, r2, mase, smape = calculate_metrics(scaler.inverse_transform(y_test.numpy().reshape(-1, 1)),scaler.inverse_transform(np.array(predictions).reshape(-1, 1)))\n","print(\"RMSE:\", rmse)\n","print(\"MSE:\", mse)\n","print(\"MAE:\", mae)\n","print(\"MAPE:\", mape)\n","print(\"R²:\", r2)\n","print(\"MASE:\", mase)\n","print(\"sMAPE:\", smape)\n","print(\"Memoria RAM: \",max(memoria_usada))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhorrskHJVxA","executionInfo":{"status":"ok","timestamp":1710727880202,"user_tz":180,"elapsed":12,"user":{"displayName":"Ricardo Adley","userId":"12542844481650779199"}},"outputId":"375a0fce-ebc2-48cd-df92-78ca912a911d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 74.55555952253076\n","MSE: 5558.531455717627\n","MAE: 44.07882405005383\n","MAPE: 3.617682213975991\n","R²: 0.9456787940606953\n","MASE: inf\n","sMAPE: 3.6972210642514853\n","Memoria RAM:  1555111936\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-e5c6de39bd21>:25: RuntimeWarning: divide by zero encountered in divide\n","  mase = np.mean(np.abs(observed_values - predicted_values) / naive_errors)\n"]}]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/jeffheaton/app_deep_learning/blob/main/t81_558_class_10_3_transformer_timeseries.ipynb","timestamp":1708725845705}]},"kernelspec":{"display_name":"Python 3.11 (torch)","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}